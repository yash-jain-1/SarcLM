{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yash-jain-1/SarcLM/blob/main/notebooks/LLaVA_Fine_tuning_with_PEFT_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ocl6OYkmNUPQ",
        "outputId": "cc352286-394e-4092-924b-6b212deb6676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.6/564.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.2 setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "0c89cae4e0954e138228c8d7dfe21a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: hf_xet in /usr/local/lib/python3.12/dist-packages (1.1.10)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run only if not already installed)\n",
        "%pip install -q -U transformers datasets accelerate peft bitsandbytes trl pyarrow==19.0.0\n",
        "%pip install -U pip setuptools wheel\n",
        "%pip install bitsandbytes\n",
        "%pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DR9TfOdDxED6"
      },
      "outputs": [],
      "source": [
        "! pip install -q -U transformers datasets accelerate peft bitsandbytes trl pyarrow==19.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "41D2Q77rozYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495e1995-76ae-402c-cb8b-a73a30156f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting comm>=0.1.3 (from ipywidgets)\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (80.9.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jedi, comm, ipywidgets\n",
            "\u001b[2K  Attempting uninstall: widgetsnbextension\n",
            "\u001b[2K    Found existing installation: widgetsnbextension 3.6.10\n",
            "\u001b[2K    Uninstalling widgetsnbextension-3.6.10:\n",
            "\u001b[2K      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "\u001b[2K  Attempting uninstall: ipywidgets\n",
            "\u001b[2K    Found existing installation: ipywidgets 7.7.1\n",
            "\u001b[2K    Uninstalling ipywidgets-7.7.1:\n",
            "\u001b[2K      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [ipywidgets]\n",
            "\u001b[1A\u001b[2KSuccessfully installed comm-0.2.3 ipywidgets-8.1.7 jedi-0.19.2 widgetsnbextension-4.0.14\n"
          ]
        }
      ],
      "source": [
        "%pip install -U ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zbw5YPzBozYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc87784c-5d33-4555-e01c-6337e2fd7ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LHDLdz3fDART"
      },
      "outputs": [],
      "source": [
        "# robust_llava_loader.py\n",
        "# Loads a LLaVA-style model even when AutoModelForCausalLM doesn't recognize LlavaConfig.\n",
        "# Requires: transformers, torch, datasets, peft, trl, etc.\n",
        "# Make sure to run: pip install -U \"transformers>=4.31.0\" bitsandbytes peft trl datasets safetensors\n",
        "# if you want 4-bit quantization support (and bitsandbytes installed).\n",
        "\n",
        "import importlib\n",
        "import sys\n",
        "import traceback\n",
        "import random\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig  # if bitsandbytes present; import may fail if not installed\n",
        "from datasets import load_dataset\n",
        "\n",
        "# CONFIG\n",
        "BASE_MODEL_NAME = \"llava-hf/llava-1.5-7b-hf\"\n",
        "USE_4BIT = False  # set True only if bitsandbytes is installed & you want 4-bit quant\n",
        "DEVICE_MAP = \"auto\"\n",
        "LOW_CPU_MEM = True\n",
        "\n",
        "def print_versions():\n",
        "    print(\"torch:\", torch.__version__)\n",
        "    print(\"transformers:\", transformers.__version__)\n",
        "    try:\n",
        "        import bitsandbytes as bnb\n",
        "        print(\"bitsandbytes:\", bnb.__version__)\n",
        "    except Exception:\n",
        "        print(\"bitsandbytes: NOT INSTALLED\")\n",
        "\n",
        "def try_load_llava_class_and_model(model_name, quant_config=None, device_map=\"auto\", low_cpu_mem=True):\n",
        "    candidate_module_paths = [\n",
        "        \"transformers.models.llava.modeling_llava\",\n",
        "        \"transformers.models.llava.modeling_llava_for_causal_lm\",\n",
        "        \"llava.modeling_llava\",\n",
        "        \"modeling_llava\",\n",
        "    ]\n",
        "    candidate_class_names = [\n",
        "        \"LlavaForCausalLM\",\n",
        "        \"LlavaModelForCausalLM\",\n",
        "        \"LlavaForConditionalGeneration\",\n",
        "        \"LlavaModel\",\n",
        "        \"LlavaForVision2Seq\",\n",
        "    ]\n",
        "\n",
        "    last_exc = None\n",
        "    for mod_path in candidate_module_paths:\n",
        "        try:\n",
        "            module = importlib.import_module(mod_path)\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            continue\n",
        "\n",
        "        for cls_name in candidate_class_names:\n",
        "            ModelClass = getattr(module, cls_name, None)\n",
        "            if ModelClass is None:\n",
        "                continue\n",
        "\n",
        "            # Try strategy sequence:\n",
        "            # 1) If quant_config provided -> try direct (fast path)\n",
        "            # 2) If ValueError complaining about dispatch -> retry with llm_int8_enable_fp32_cpu_offload + device_map=\"auto\"\n",
        "            # 3) If still failing -> fallback to no-quant (float16)\n",
        "            try:\n",
        "                print(f\"Trying to load {cls_name} with device_map={device_map} (quant_config={'yes' if quant_config else 'no'})...\")\n",
        "                return _attempt_from_pretrained(ModelClass, model_name, quant_config, device_map, low_cpu_mem, extra_kwargs={})\n",
        "            except Exception as e:\n",
        "                last_exc = e\n",
        "                tb = traceback.format_exc()\n",
        "                print(f\"Initial attempt with {cls_name} failed: {e}\\n{tb}\")\n",
        "\n",
        "                # If message suggests offload, try offload route (only if quant_config not None)\n",
        "                msg = str(e).lower()\n",
        "                if quant_config is not None and (\"offload\" in msg or \"dispatched on the cpu\" in msg or \"some modules are dispatched\" in msg):\n",
        "                    try:\n",
        "                        print(\"Retrying with llm_int8_enable_fp32_cpu_offload=True and device_map='auto'...\")\n",
        "                        return ModelClass.from_pretrained(\n",
        "                            model_name,\n",
        "                            quantization_config=quant_config,\n",
        "                            device_map=\"auto\",\n",
        "                            trust_remote_code=True,\n",
        "                            low_cpu_mem_usage=low_cpu_mem,\n",
        "                            llm_int8_enable_fp32_cpu_offload=True,\n",
        "                        )\n",
        "                    except Exception as e2:\n",
        "                        last_exc = e2\n",
        "                        tb2 = traceback.format_exc()\n",
        "                        print(f\"Retry with offload failed: {e2}\\n{tb2}\")\n",
        "\n",
        "                # Final fallback: try without quantization (float16)\n",
        "                try:\n",
        "                    print(\"Retrying without quantization (float16) as a fallback...\")\n",
        "                    return ModelClass.from_pretrained(\n",
        "                        model_name,\n",
        "                        device_map=device_map,\n",
        "                        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                        trust_remote_code=True,\n",
        "                        low_cpu_mem_usage=low_cpu_mem,\n",
        "                    )\n",
        "                except Exception as e3:\n",
        "                    last_exc = e3\n",
        "                    tb3 = traceback.format_exc()\n",
        "                    print(f\"Fallback without quantization also failed: {e3}\\n{tb3}\")\n",
        "                    continue\n",
        "\n",
        "    raise RuntimeError(\"Tried candidate Llava classes but all failed. Last exception:\\n\" + (str(last_exc) if last_exc is not None else \"None\"))\n",
        "\n",
        "def _attempt_from_pretrained(ModelClass, model_name, quant_config, device_map, low_cpu_mem, extra_kwargs):\n",
        "    \"\"\"Helper to call from_pretrained with given kwargs and bubble exceptions.\"\"\"\n",
        "    try:\n",
        "        if quant_config is not None:\n",
        "            return ModelClass.from_pretrained(\n",
        "                model_name,\n",
        "                quantization_config=quant_config,\n",
        "                device_map=device_map,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=low_cpu_mem,\n",
        "                **extra_kwargs,\n",
        "            )\n",
        "        else:\n",
        "            return ModelClass.from_pretrained(\n",
        "                model_name,\n",
        "                device_map=device_map,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=low_cpu_mem,\n",
        "                **extra_kwargs,\n",
        "            )\n",
        "    except Exception as e:\n",
        "        raise\n",
        "\n",
        "def load_model_and_tokenizer(model_name, use_4bit=True, device_map=\"auto\", low_cpu_mem=True):\n",
        "    # Load config + tokenizer\n",
        "    config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    quant_config = None\n",
        "    if use_4bit:\n",
        "        try:\n",
        "            quant_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Could not create BitsAndBytesConfig:\", e)\n",
        "            quant_config = None\n",
        "\n",
        "    # If LlavaConfig detected: try repo model classes (with fallback paths)\n",
        "    cfg_name = config.__class__.__name__.lower()\n",
        "    if \"llava\" in cfg_name:\n",
        "        model = try_load_llava_class_and_model(model_name, quant_config=quant_config, device_map=device_map, low_cpu_mem=low_cpu_mem)\n",
        "    else:\n",
        "        # generic fallback to AutoModelForCausalLM\n",
        "        if quant_config is not None:\n",
        "            try:\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    model_name,\n",
        "                    quantization_config=quant_config,\n",
        "                    device_map=device_map,\n",
        "                    trust_remote_code=True,\n",
        "                    low_cpu_mem_usage=low_cpu_mem,\n",
        "                    llm_int8_enable_fp32_cpu_offload=True,  # safe to include\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\"AutoModelForCausalLM with quant failed, retrying without quant:\", e)\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    model_name,\n",
        "                    device_map=device_map,\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    trust_remote_code=True,\n",
        "                    low_cpu_mem_usage=low_cpu_mem,\n",
        "                )\n",
        "        else:\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                device_map=device_map,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=low_cpu_mem,\n",
        "            )\n",
        "\n",
        "    try:\n",
        "        model.gradient_checkpointing_enable()\n",
        "    except Exception:\n",
        "        pass\n",
        "    model.config.use_cache = False\n",
        "    return model, tokenizer\n",
        "\n",
        "# Now, when you run main(), it will automatically retry with llm_int8_enable_fp32_cpu_offload if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r86yQYcGDDQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef25318-7fb8-49a6-8521-af00e42cfcdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Running in Colab. You may use Colab resources.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Running in Colab. You may use Colab resources.\")\n",
        "    # Optionally: get API key from user input or environment\n",
        "    # api_key = input(\"Enter your API key: \")\n",
        "else:\n",
        "    print(\"Not running in Colab. Using local environment.\")\n",
        "    # Optionally: get API key from environment variable\n",
        "    # api_key = os.getenv(\"YOUR_API_KEY_ENV_VAR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "evPygyPuUVXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5613a6c3ccd4077ba3b453d07fdda93",
            "0a9e5dcada3f439d85db8f5fcb013994",
            "8b63505faecd4cb3bf6740dd7c3d7cfb",
            "2f34c26d434546e5a9788e22b6556187",
            "6b7986ae63c940f98d85183bf51d1835",
            "9ad458f171e34f0ea30b1f7940dd3728",
            "e2d98cb4daa94d81aed7d5c6107e39ea",
            "e29c7397e341446b84390c1631351c1a",
            "84e099d27c5c49f19a81a23d1db502aa",
            "75675b02d22f40fbbb27c2cc212522b6",
            "69359fafe2b44b85978372ffcd8e4795"
          ]
        },
        "outputId": "18dc72a8-5c71-4989-cb24-9909bcc8e087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model + tokenizer (robust loader)...\n",
            "Trying to load LlavaForConditionalGeneration with device_map=auto (quant_config=yes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5613a6c3ccd4077ba3b453d07fdda93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model and tokenizer. Model dtype hint: torch.float16\n",
            "Auto-detecting candidate LoRA target module name tokens from model.named_modules()...\n",
            "Detected target-module name tokens (candidates): ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\n",
            "Preparing model for k-bit training (peft.prepare_model_for_kbit_training)...\n",
            "Applying LoRA with LoraConfig: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=64, target_modules={'o_proj', 'k_proj', 'up_proj', 'gate_proj', 'q_proj', 'v_proj', 'down_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)\n",
            "PEFT/LoRA applied. Peft model keys: [('base_model.model.model.vision_tower.vision_model.embeddings.class_embedding', Parameter containing:\n",
            "tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],\n",
            "       device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.embeddings.patch_embedding.weight', Parameter containing:\n",
            "tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,\n",
            "            2.1957e-02,  5.0011e-03],\n",
            "          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,\n",
            "            7.5417e-03, -1.2230e-02],\n",
            "          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,\n",
            "            5.3940e-03, -1.2283e-02],\n",
            "          ...,\n",
            "          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,\n",
            "           -2.3239e-02, -2.4017e-02],\n",
            "          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,\n",
            "            1.5745e-03, -4.1771e-03],\n",
            "          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,\n",
            "            4.0169e-03, -6.7177e-03]],\n",
            "\n",
            "         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,\n",
            "            2.4185e-02,  5.8136e-03],\n",
            "          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,\n",
            "            5.4970e-03, -1.4351e-02],\n",
            "          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,\n",
            "            5.5618e-03, -1.2390e-02],\n",
            "          ...,\n",
            "          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,\n",
            "            3.9816e-04, -5.1346e-03],\n",
            "          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,\n",
            "            2.2552e-02,  1.2917e-02],\n",
            "          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,\n",
            "            1.8158e-02,  9.2745e-04]],\n",
            "\n",
            "         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,\n",
            "            1.1757e-02,  5.7259e-03],\n",
            "          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,\n",
            "           -4.2191e-03, -7.1831e-03],\n",
            "          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,\n",
            "            1.3041e-04, -7.3051e-03],\n",
            "          ...,\n",
            "          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,\n",
            "           -9.8267e-03, -6.7825e-03],\n",
            "          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,\n",
            "            6.3400e-03,  5.3177e-03],\n",
            "          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,\n",
            "            6.5193e-03,  2.9850e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,\n",
            "           -8.4381e-03,  2.0447e-02],\n",
            "          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,\n",
            "            3.5906e-04,  1.5945e-02],\n",
            "          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,\n",
            "           -2.7924e-02, -3.2177e-03],\n",
            "          ...,\n",
            "          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,\n",
            "           -5.4741e-03, -5.9624e-03],\n",
            "          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,\n",
            "           -2.7969e-02, -1.8875e-02],\n",
            "          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,\n",
            "            7.1335e-03,  4.6478e-02]],\n",
            "\n",
            "         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,\n",
            "           -1.1604e-02,  1.7593e-02],\n",
            "          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,\n",
            "            3.4976e-04,  1.4732e-02],\n",
            "          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,\n",
            "           -3.2684e-02, -7.0076e-03],\n",
            "          ...,\n",
            "          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,\n",
            "           -1.1253e-02, -9.8648e-03],\n",
            "          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,\n",
            "           -3.7231e-02, -2.6505e-02],\n",
            "          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,\n",
            "           -4.2000e-03,  3.9368e-02]],\n",
            "\n",
            "         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,\n",
            "           -1.2558e-02,  1.7303e-02],\n",
            "          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,\n",
            "            4.3440e-04,  1.5656e-02],\n",
            "          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,\n",
            "           -2.9968e-02, -6.5422e-03],\n",
            "          ...,\n",
            "          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,\n",
            "           -8.7967e-03, -8.7662e-03],\n",
            "          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,\n",
            "           -3.0518e-02, -2.4918e-02],\n",
            "          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,\n",
            "           -7.3242e-04,  3.8818e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,\n",
            "            1.4229e-02,  1.8768e-02],\n",
            "          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,\n",
            "            5.4283e-03,  6.6032e-03],\n",
            "          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,\n",
            "            2.5959e-03,  6.8703e-03],\n",
            "          ...,\n",
            "          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,\n",
            "            1.4397e-02,  1.2421e-02],\n",
            "          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,\n",
            "            2.2766e-02,  2.2659e-02],\n",
            "          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,\n",
            "            2.2263e-02,  2.5238e-02]],\n",
            "\n",
            "         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,\n",
            "            1.9653e-02,  2.8290e-02],\n",
            "          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,\n",
            "            6.0501e-03,  1.2810e-02],\n",
            "          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,\n",
            "           -5.9271e-04,  8.8959e-03],\n",
            "          ...,\n",
            "          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,\n",
            "            2.4902e-02,  2.6871e-02],\n",
            "          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,\n",
            "            3.3569e-02,  3.9612e-02],\n",
            "          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,\n",
            "            3.9276e-02,  4.6051e-02]],\n",
            "\n",
            "         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,\n",
            "            2.1042e-02,  2.9053e-02],\n",
            "          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,\n",
            "            7.7019e-03,  1.2169e-02],\n",
            "          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,\n",
            "            3.3913e-03,  9.0408e-03],\n",
            "          ...,\n",
            "          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,\n",
            "            8.0795e-03,  1.4221e-02],\n",
            "          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,\n",
            "            1.1887e-02,  1.8204e-02],\n",
            "          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,\n",
            "            1.5701e-02,  2.2247e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,\n",
            "            3.1686e-04, -3.0446e-04],\n",
            "          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,\n",
            "           -2.2995e-04, -1.6510e-04],\n",
            "          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,\n",
            "           -5.0831e-04,  5.9748e-04],\n",
            "          ...,\n",
            "          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,\n",
            "           -9.3746e-04, -6.7472e-04],\n",
            "          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,\n",
            "           -1.4048e-03, -1.3056e-03],\n",
            "          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,\n",
            "            3.2640e-04,  1.7679e-04]],\n",
            "\n",
            "         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,\n",
            "            1.0500e-03, -5.0831e-04],\n",
            "          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,\n",
            "            1.0071e-03, -4.9925e-04],\n",
            "          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,\n",
            "            8.0919e-04,  9.7132e-04],\n",
            "          ...,\n",
            "          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,\n",
            "            6.2895e-04,  4.0889e-04],\n",
            "          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,\n",
            "           -2.8610e-04,  1.9038e-04],\n",
            "          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,\n",
            "            1.4138e-04,  4.2319e-04]],\n",
            "\n",
            "         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,\n",
            "           -4.3130e-04, -5.6791e-04],\n",
            "          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,\n",
            "            1.9002e-04,  1.8311e-04],\n",
            "          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,\n",
            "            2.3186e-05, -5.7578e-05],\n",
            "          ...,\n",
            "          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,\n",
            "            1.3471e-04,  6.5708e-04],\n",
            "          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,\n",
            "            1.0538e-04, -4.9019e-04],\n",
            "          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,\n",
            "           -4.1580e-04,  5.5599e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,\n",
            "            6.1874e-03,  2.6535e-02],\n",
            "          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,\n",
            "           -1.7639e-02, -3.2768e-03],\n",
            "          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,\n",
            "           -2.7237e-02, -5.5046e-03],\n",
            "          ...,\n",
            "          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,\n",
            "            2.8503e-02,  3.6499e-02],\n",
            "          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,\n",
            "           -2.3010e-02,  5.0926e-03],\n",
            "          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,\n",
            "           -3.9276e-02,  1.3908e-02]],\n",
            "\n",
            "         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,\n",
            "            2.8896e-03,  2.2415e-02],\n",
            "          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,\n",
            "           -1.8616e-02, -6.5308e-03],\n",
            "          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,\n",
            "           -3.0472e-02, -9.3613e-03],\n",
            "          ...,\n",
            "          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,\n",
            "            2.6001e-02,  3.4241e-02],\n",
            "          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,\n",
            "           -3.0487e-02, -9.5701e-04],\n",
            "          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,\n",
            "           -5.1422e-02,  4.2267e-03]],\n",
            "\n",
            "         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,\n",
            "           -2.1572e-03,  1.6891e-02],\n",
            "          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,\n",
            "           -2.1347e-02, -9.2316e-03],\n",
            "          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,\n",
            "           -2.9694e-02, -1.2733e-02],\n",
            "          ...,\n",
            "          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,\n",
            "            1.9257e-02,  2.4582e-02],\n",
            "          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,\n",
            "           -3.1281e-02, -9.1248e-03],\n",
            "          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,\n",
            "           -5.2246e-02, -2.8057e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,\n",
            "            8.1863e-03, -4.8248e-02],\n",
            "          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,\n",
            "            9.3689e-03, -3.8544e-02],\n",
            "          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,\n",
            "            2.3956e-02, -1.1154e-02],\n",
            "          ...,\n",
            "          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,\n",
            "           -1.8654e-03, -1.9440e-02],\n",
            "          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,\n",
            "            8.4381e-03,  1.4282e-02],\n",
            "          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,\n",
            "            1.6689e-03,  1.6891e-02]],\n",
            "\n",
            "         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,\n",
            "            1.5839e-02, -4.3243e-02],\n",
            "          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,\n",
            "            1.8433e-02, -3.1799e-02],\n",
            "          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,\n",
            "            2.9694e-02, -5.4817e-03],\n",
            "          ...,\n",
            "          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,\n",
            "           -1.5268e-03, -1.4626e-02],\n",
            "          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,\n",
            "            8.5602e-03,  2.0035e-02],\n",
            "          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,\n",
            "           -2.3785e-03,  1.9150e-02]],\n",
            "\n",
            "         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,\n",
            "            2.1317e-02, -3.0197e-02],\n",
            "          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,\n",
            "            2.4658e-02, -1.7670e-02],\n",
            "          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,\n",
            "            3.4302e-02,  4.5395e-03],\n",
            "          ...,\n",
            "          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,\n",
            "            4.1656e-03, -5.9814e-03],\n",
            "          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,\n",
            "            1.6068e-02,  2.5879e-02],\n",
            "          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,\n",
            "            2.2964e-03,  2.2339e-02]]]], device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.embeddings.position_embedding.weight', Parameter containing:\n",
            "tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],\n",
            "        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],\n",
            "        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],\n",
            "        ...,\n",
            "        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],\n",
            "        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],\n",
            "        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],\n",
            "       device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.pre_layrnorm.weight', Parameter containing:\n",
            "tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044], device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.pre_layrnorm.bias', Parameter containing:\n",
            "tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],\n",
            "       device='cuda:0'))]\n",
            "Loading dataset from meld_with_rationales.jsonl\n",
            "Dataset size: 100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SFTConfig.__init__() got an unexpected keyword argument 'max_seq_length'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1811879401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1811879401.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# 6) SFTConfig + trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     training_args = SFTConfig(\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SFTConfig.__init__() got an unexpected keyword argument 'max_seq_length'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "finetune_after_script_b.py\n",
        "\n",
        "Uses robust_llava_loader.load_model_and_tokenizer() (script B output) to load the model,\n",
        "auto-detects good LoRA target_modules, and runs PEFT (LoRA) fine-tuning with trl.SFTTrainer.\n",
        "\n",
        "Usage: python finetune_after_script_b.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "\n",
        "# try to import helper for preparing k-bit training (peft versions vary)\n",
        "try:\n",
        "    from peft import prepare_model_for_kbit_training\n",
        "except Exception:\n",
        "    try:\n",
        "        from peft.utils import prepare_model_for_kbit_training\n",
        "    except Exception:\n",
        "        prepare_model_for_kbit_training = None\n",
        "\n",
        "# Add the src directory to the Python path so we can import robust_llava_loader\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))\n",
        "from robust_llava_loader import load_model_and_tokenizer\n",
        "\n",
        "# --------------------- USER CONFIG ---------------------\n",
        "BASE_MODEL_NAME = \"llava-hf/llava-1.5-7b-hf\"\n",
        "DATASET_PATH = \"meld_with_rationales.jsonl\"   # jsonl containing utterance, sentiment, rationale\n",
        "OUTPUT_DIR = \"./llava-peft-adapters-auto\"\n",
        "USE_4BIT_IF_AVAILABLE = True\n",
        "MAX_SEQ_LENGTH = 512\n",
        "PER_DEVICE_BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 2e-4\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "SAVE_STEPS = 200\n",
        "LOGGING_STEPS = 20\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# helper: create the training prompt\n",
        "def build_prompt(example):\n",
        "    return (\n",
        "        \"You are a sentiment analysis expert. Analyze the following utterance and provide \"\n",
        "        \"the sentiment along with a step-by-step rationale for your decision.\\n\\n\"\n",
        "        \"### Utterance:\\n\"\n",
        "        f\"{example.get('utterance','')}\\n\\n\"\n",
        "        \"### Analysis:\\n\"\n",
        "        f\"Sentiment: {example.get('sentiment','')}\\n\"\n",
        "        f\"Rationale: {example.get('rationale','')}\"\n",
        "    )\n",
        "\n",
        "# helper: scan model.named_modules() and choose candidate target module name substrings\n",
        "def auto_detect_target_module_names(model, prefer_text=True):\n",
        "    \"\"\"\n",
        "    Returns a list of module-name substrings to use in LoraConfig.target_modules.\n",
        "    Strategy:\n",
        "      - Collect names of submodules that look like projections (q_proj, k_proj, v_proj, out_proj, o_proj)\n",
        "      - Prefer modules under 'model' that contain tokens like 'self_attn', 'attn', 'q_proj' etc.\n",
        "      - If prefer_text=True, try to exclude modules under vision tower (module name containing 'vision' or 'vision_tower')\n",
        "    \"\"\"\n",
        "    proj_patterns = set()\n",
        "    name_list = [n for n, _ in model.named_modules()]\n",
        "\n",
        "    for n in name_list:\n",
        "        # skip top-level empty name\n",
        "        if not n:\n",
        "            continue\n",
        "        # skip vision modules if preferring text modules\n",
        "        if prefer_text and (\"vision\" in n or \"vision_tower\" in n or \"vision_model\" in n):\n",
        "            continue\n",
        "        # find typical projection/fc names in module path\n",
        "        if re.search(r\"(q_proj|k_proj|v_proj|o_proj|out_proj|gate_proj|up_proj|down_proj|fc1|fc2)\", n):\n",
        "            # extract final token (last part after '.')\n",
        "            final = n.split(\".\")[-1]\n",
        "            proj_patterns.add(final)\n",
        "    # fallback if empty\n",
        "    if not proj_patterns:\n",
        "        # default common names\n",
        "        proj_patterns = {\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"}\n",
        "    # keep consistent ordering and return as list\n",
        "    return sorted(list(proj_patterns))\n",
        "\n",
        "def format_and_map(example, tokenizer):\n",
        "    text = build_prompt(example)\n",
        "    eos = tokenizer.eos_token or \"\"\n",
        "    return {\"text\": text + eos}\n",
        "\n",
        "def main():\n",
        "    # decide 4-bit usage\n",
        "    use_4bit = False\n",
        "    if USE_4BIT_IF_AVAILABLE:\n",
        "        try:\n",
        "            import bitsandbytes  # noqa: F401\n",
        "            use_4bit = True\n",
        "        except Exception:\n",
        "            print(\"bitsandbytes not installed/found — running without 4-bit.\")\n",
        "\n",
        "    # 1) Load model + tokenizer (robust loader)\n",
        "    print(\"Loading model + tokenizer (robust loader)...\")\n",
        "    model, tokenizer = load_model_and_tokenizer(model_name=BASE_MODEL_NAME, use_4bit=use_4bit)\n",
        "    print(\"Loaded model and tokenizer. Model dtype hint:\", getattr(model, \"dtype\", None))\n",
        "    model.config.use_cache = False\n",
        "    try:\n",
        "        model.gradient_checkpointing_enable()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) Auto-detect target_modules for LoRA (based on model module names)\n",
        "    print(\"Auto-detecting candidate LoRA target module name tokens from model.named_modules()...\")\n",
        "    detected = auto_detect_target_module_names(model, prefer_text=True)\n",
        "    print(\"Detected target-module name tokens (candidates):\", detected)\n",
        "\n",
        "    # We'll use these tokens as LoraConfig.target_modules (PEFT expects substrings)\n",
        "    target_modules = detected\n",
        "\n",
        "    # 3) Prepare model for k-bit training (if using 4-bit & helper present)\n",
        "    if use_4bit:\n",
        "        if prepare_model_for_kbit_training is not None:\n",
        "            print(\"Preparing model for k-bit training (peft.prepare_model_for_kbit_training)...\")\n",
        "            model = prepare_model_for_kbit_training(model)\n",
        "        else:\n",
        "            print(\"prepare_model_for_kbit_training not available in this peft version — continuing.\")\n",
        "\n",
        "    # 4) Create LoraConfig and wrap model\n",
        "    lora_cfg = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=target_modules,\n",
        "    )\n",
        "    print(\"Applying LoRA with LoraConfig:\", lora_cfg)\n",
        "    model = get_peft_model(model, lora_cfg)\n",
        "    print(\"PEFT/LoRA applied. Peft model keys:\", list(model.named_parameters())[:5])\n",
        "\n",
        "    # 5) Load and format dataset\n",
        "    print(\"Loading dataset from\", DATASET_PATH)\n",
        "    ds = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n",
        "    print(\"Dataset size:\", len(ds))\n",
        "    # map to `text` field expected by SFTTrainer\n",
        "    ds = ds.map(lambda ex: format_and_map(ex, tokenizer), remove_columns=ds.column_names)\n",
        "\n",
        "    # import here to avoid top-level dependency until needed\n",
        "    from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "    # 6) SFTConfig + trainer\n",
        "    training_args = SFTConfig(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=use_4bit or (torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory >= 12 * 1024 ** 2),\n",
        "        save_steps=SAVE_STEPS,\n",
        "        logging_steps=LOGGING_STEPS,\n",
        "        save_total_limit=3,\n",
        "        report_to=\"none\",\n",
        "        dataset_text_field=\"text\",\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        packing=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=ds,\n",
        "        peft_config=lora_cfg,\n",
        "        tokenizer=tokenizer,\n",
        "        args=training_args, # Pass the SFTConfig object here\n",
        "    )\n",
        "\n",
        "    # 7) Dry-run: single step to validate forward/backward\n",
        "    print(\"Running a 1-step dry-run to validate training loop...\")\n",
        "    try:\n",
        "        trainer.train(max_steps=1)\n",
        "        print(\"Dry-run succeeded.\")\n",
        "    except Exception as e:\n",
        "        print(\"Dry-run failed — inspect traceback. Error:\", e)\n",
        "        raise\n",
        "\n",
        "    # 8) Full training\n",
        "    print(\"Starting full training...\")\n",
        "    trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    # 9) Save PEFT adapters\n",
        "    print(\"Saving adapters to:\", OUTPUT_DIR)\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    print(\"Saved. You can load later with PeftModel.from_pretrained(base_model, OUTPUT_DIR)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YAFcBo8uVALa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5f9d29d9ecb043818ade133cd44a84c8",
            "4eb2a98706d149f3bc80793b43598fc2",
            "6602f1f73dc24fa29191632bb86f2993",
            "1c2b29a5025b4bfcb71546e23eded53f",
            "ac06103a3c5b4c0994e9965d00907e55",
            "b2ff0ce8fae5450f8e2d801a3666f3af",
            "8215fd903942432ab6d70049c9a5e656",
            "eb05168b9551472fa93e7b1e97bcb598",
            "9f7e3ec938e940c8b0befca6351e6277",
            "bebf5287de214b08b8a42d8f8300a01d",
            "76e80cef4cb44cca9a651df506f44b78",
            "9828872695fc4c268241a1fb583c5691",
            "624b6256c73b4badbf0ea1e2026ab204",
            "c1d5a7ec2f814aa18b9f3b041bbe19d5",
            "326252cc1c9a4a548408c1fbc3395fa7",
            "a5fa9b4432064e738ada0d69c45f2941",
            "1c21f344cac14ea2b3fc3016a47d7870",
            "8cb466006d51468ea5b241701a62ab6b",
            "36e8f1435ef14fd5bbe70ea397b7e09a",
            "e25c80ce5feb4c49ba2aa50f86443011",
            "8fbe14b3c1554fce81ef4e902d680266",
            "08552dc1c36a4153bcaed83ec3aea202",
            "aaea884b6a2a4ab18feff3db5fd43d0a",
            "32be4ec15ba046c88ba26908dfcaf9f2",
            "18dbeb143c7a457b869ccead604a2a29",
            "7ae6dd6740e345b59bbea028026513b4",
            "6d673d0921a54fe29039fc3b740abbcf",
            "c5da97db2cec462b8bdeaac55d48a736",
            "44058f2163494f848e1e4cabee4f418c",
            "8fb70fe7dfa84d07ba932164ea49e53b",
            "bcf3f88cf07f431ebfbea9245efe801e",
            "cd6c9fd3d0f24a74b937a2c477890aed",
            "bb3e34d6d27e400a9e7688281da2e1cf",
            "98d1338352e0484d9ddd81a577c294dd",
            "a1c47b8f14ac43aea15fb921b717412a",
            "dad139611a2e407896f092cd45d9bdfa",
            "5cb964ba59124904849432fda04e80d1",
            "dc60ab6fe8124d68b35b7d0e894f42f5",
            "8deaa933b8d1471d8bbcf1931a9ffe5b",
            "87df1593c01c446d9d1bd5d6567c76d3",
            "028c322ddfb341bca627af68cc716696",
            "caffd49dd29c4883ba9e2030fa376893",
            "25d838218df240d7a63614684962e51b",
            "1f93f758b700410f9989b07962f73104",
            "3820e8d0750d429a8d7f2be468fb1caf",
            "80d5bb880fde440ca413bee05215954d",
            "7d73e350223946d7a7962e1e8c7f4349",
            "e155cac6392144f68b6cff4d82967005",
            "20f947c000484b1b9606dc8fb214cd55",
            "2ec0afbf9b654fe2af55fc93930d8b94",
            "31cb9ebb639f4bd9b992cc93a4348095",
            "b632d5cb63834322b0b4acad68747956",
            "1e44da19bd114543b97832352af10e1b",
            "bb88b1daac4240acb771cb523f7d3634",
            "c1a9bd5992274b23aa58b30f621c8252"
          ]
        },
        "outputId": "43461b78-b014-4bdd-89be-c9443f3aec71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model + tokenizer (robust loader)...\n",
            "Trying to load LlavaForConditionalGeneration with device_map=auto (quant_config=yes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f9d29d9ecb043818ade133cd44a84c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model and tokenizer. Model dtype hint: torch.float16\n",
            "Auto-detecting candidate LoRA target module name tokens from model.named_modules()...\n",
            "Detected target-module name tokens (candidates): ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\n",
            "Preparing model for k-bit training (peft.prepare_model_for_kbit_training)...\n",
            "Applying LoRA with LoraConfig: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=64, target_modules={'up_proj', 'v_proj', 'o_proj', 'down_proj', 'k_proj', 'gate_proj', 'q_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)\n",
            "PEFT/LoRA applied. Peft model keys: [('base_model.model.model.vision_tower.vision_model.embeddings.class_embedding', Parameter containing:\n",
            "tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],\n",
            "       device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.embeddings.patch_embedding.weight', Parameter containing:\n",
            "tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,\n",
            "            2.1957e-02,  5.0011e-03],\n",
            "          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,\n",
            "            7.5417e-03, -1.2230e-02],\n",
            "          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,\n",
            "            5.3940e-03, -1.2283e-02],\n",
            "          ...,\n",
            "          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,\n",
            "           -2.3239e-02, -2.4017e-02],\n",
            "          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,\n",
            "            1.5745e-03, -4.1771e-03],\n",
            "          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,\n",
            "            4.0169e-03, -6.7177e-03]],\n",
            "\n",
            "         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,\n",
            "            2.4185e-02,  5.8136e-03],\n",
            "          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,\n",
            "            5.4970e-03, -1.4351e-02],\n",
            "          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,\n",
            "            5.5618e-03, -1.2390e-02],\n",
            "          ...,\n",
            "          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,\n",
            "            3.9816e-04, -5.1346e-03],\n",
            "          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,\n",
            "            2.2552e-02,  1.2917e-02],\n",
            "          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,\n",
            "            1.8158e-02,  9.2745e-04]],\n",
            "\n",
            "         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,\n",
            "            1.1757e-02,  5.7259e-03],\n",
            "          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,\n",
            "           -4.2191e-03, -7.1831e-03],\n",
            "          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,\n",
            "            1.3041e-04, -7.3051e-03],\n",
            "          ...,\n",
            "          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,\n",
            "           -9.8267e-03, -6.7825e-03],\n",
            "          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,\n",
            "            6.3400e-03,  5.3177e-03],\n",
            "          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,\n",
            "            6.5193e-03,  2.9850e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,\n",
            "           -8.4381e-03,  2.0447e-02],\n",
            "          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,\n",
            "            3.5906e-04,  1.5945e-02],\n",
            "          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,\n",
            "           -2.7924e-02, -3.2177e-03],\n",
            "          ...,\n",
            "          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,\n",
            "           -5.4741e-03, -5.9624e-03],\n",
            "          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,\n",
            "           -2.7969e-02, -1.8875e-02],\n",
            "          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,\n",
            "            7.1335e-03,  4.6478e-02]],\n",
            "\n",
            "         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,\n",
            "           -1.1604e-02,  1.7593e-02],\n",
            "          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,\n",
            "            3.4976e-04,  1.4732e-02],\n",
            "          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,\n",
            "           -3.2684e-02, -7.0076e-03],\n",
            "          ...,\n",
            "          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,\n",
            "           -1.1253e-02, -9.8648e-03],\n",
            "          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,\n",
            "           -3.7231e-02, -2.6505e-02],\n",
            "          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,\n",
            "           -4.2000e-03,  3.9368e-02]],\n",
            "\n",
            "         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,\n",
            "           -1.2558e-02,  1.7303e-02],\n",
            "          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,\n",
            "            4.3440e-04,  1.5656e-02],\n",
            "          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,\n",
            "           -2.9968e-02, -6.5422e-03],\n",
            "          ...,\n",
            "          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,\n",
            "           -8.7967e-03, -8.7662e-03],\n",
            "          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,\n",
            "           -3.0518e-02, -2.4918e-02],\n",
            "          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,\n",
            "           -7.3242e-04,  3.8818e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,\n",
            "            1.4229e-02,  1.8768e-02],\n",
            "          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,\n",
            "            5.4283e-03,  6.6032e-03],\n",
            "          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,\n",
            "            2.5959e-03,  6.8703e-03],\n",
            "          ...,\n",
            "          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,\n",
            "            1.4397e-02,  1.2421e-02],\n",
            "          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,\n",
            "            2.2766e-02,  2.2659e-02],\n",
            "          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,\n",
            "            2.2263e-02,  2.5238e-02]],\n",
            "\n",
            "         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,\n",
            "            1.9653e-02,  2.8290e-02],\n",
            "          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,\n",
            "            6.0501e-03,  1.2810e-02],\n",
            "          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,\n",
            "           -5.9271e-04,  8.8959e-03],\n",
            "          ...,\n",
            "          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,\n",
            "            2.4902e-02,  2.6871e-02],\n",
            "          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,\n",
            "            3.3569e-02,  3.9612e-02],\n",
            "          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,\n",
            "            3.9276e-02,  4.6051e-02]],\n",
            "\n",
            "         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,\n",
            "            2.1042e-02,  2.9053e-02],\n",
            "          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,\n",
            "            7.7019e-03,  1.2169e-02],\n",
            "          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,\n",
            "            3.3913e-03,  9.0408e-03],\n",
            "          ...,\n",
            "          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,\n",
            "            8.0795e-03,  1.4221e-02],\n",
            "          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,\n",
            "            1.1887e-02,  1.8204e-02],\n",
            "          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,\n",
            "            1.5701e-02,  2.2247e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,\n",
            "            3.1686e-04, -3.0446e-04],\n",
            "          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,\n",
            "           -2.2995e-04, -1.6510e-04],\n",
            "          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,\n",
            "           -5.0831e-04,  5.9748e-04],\n",
            "          ...,\n",
            "          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,\n",
            "           -9.3746e-04, -6.7472e-04],\n",
            "          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,\n",
            "           -1.4048e-03, -1.3056e-03],\n",
            "          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,\n",
            "            3.2640e-04,  1.7679e-04]],\n",
            "\n",
            "         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,\n",
            "            1.0500e-03, -5.0831e-04],\n",
            "          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,\n",
            "            1.0071e-03, -4.9925e-04],\n",
            "          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,\n",
            "            8.0919e-04,  9.7132e-04],\n",
            "          ...,\n",
            "          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,\n",
            "            6.2895e-04,  4.0889e-04],\n",
            "          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,\n",
            "           -2.8610e-04,  1.9038e-04],\n",
            "          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,\n",
            "            1.4138e-04,  4.2319e-04]],\n",
            "\n",
            "         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,\n",
            "           -4.3130e-04, -5.6791e-04],\n",
            "          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,\n",
            "            1.9002e-04,  1.8311e-04],\n",
            "          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,\n",
            "            2.3186e-05, -5.7578e-05],\n",
            "          ...,\n",
            "          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,\n",
            "            1.3471e-04,  6.5708e-04],\n",
            "          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,\n",
            "            1.0538e-04, -4.9019e-04],\n",
            "          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,\n",
            "           -4.1580e-04,  5.5599e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,\n",
            "            6.1874e-03,  2.6535e-02],\n",
            "          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,\n",
            "           -1.7639e-02, -3.2768e-03],\n",
            "          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,\n",
            "           -2.7237e-02, -5.5046e-03],\n",
            "          ...,\n",
            "          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,\n",
            "            2.8503e-02,  3.6499e-02],\n",
            "          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,\n",
            "           -2.3010e-02,  5.0926e-03],\n",
            "          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,\n",
            "           -3.9276e-02,  1.3908e-02]],\n",
            "\n",
            "         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,\n",
            "            2.8896e-03,  2.2415e-02],\n",
            "          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,\n",
            "           -1.8616e-02, -6.5308e-03],\n",
            "          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,\n",
            "           -3.0472e-02, -9.3613e-03],\n",
            "          ...,\n",
            "          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,\n",
            "            2.6001e-02,  3.4241e-02],\n",
            "          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,\n",
            "           -3.0487e-02, -9.5701e-04],\n",
            "          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,\n",
            "           -5.1422e-02,  4.2267e-03]],\n",
            "\n",
            "         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,\n",
            "           -2.1572e-03,  1.6891e-02],\n",
            "          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,\n",
            "           -2.1347e-02, -9.2316e-03],\n",
            "          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,\n",
            "           -2.9694e-02, -1.2733e-02],\n",
            "          ...,\n",
            "          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,\n",
            "            1.9257e-02,  2.4582e-02],\n",
            "          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,\n",
            "           -3.1281e-02, -9.1248e-03],\n",
            "          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,\n",
            "           -5.2246e-02, -2.8057e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,\n",
            "            8.1863e-03, -4.8248e-02],\n",
            "          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,\n",
            "            9.3689e-03, -3.8544e-02],\n",
            "          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,\n",
            "            2.3956e-02, -1.1154e-02],\n",
            "          ...,\n",
            "          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,\n",
            "           -1.8654e-03, -1.9440e-02],\n",
            "          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,\n",
            "            8.4381e-03,  1.4282e-02],\n",
            "          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,\n",
            "            1.6689e-03,  1.6891e-02]],\n",
            "\n",
            "         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,\n",
            "            1.5839e-02, -4.3243e-02],\n",
            "          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,\n",
            "            1.8433e-02, -3.1799e-02],\n",
            "          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,\n",
            "            2.9694e-02, -5.4817e-03],\n",
            "          ...,\n",
            "          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,\n",
            "           -1.5268e-03, -1.4626e-02],\n",
            "          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,\n",
            "            8.5602e-03,  2.0035e-02],\n",
            "          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,\n",
            "           -2.3785e-03,  1.9150e-02]],\n",
            "\n",
            "         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,\n",
            "            2.1317e-02, -3.0197e-02],\n",
            "          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,\n",
            "            2.4658e-02, -1.7670e-02],\n",
            "          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,\n",
            "            3.4302e-02,  4.5395e-03],\n",
            "          ...,\n",
            "          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,\n",
            "            4.1656e-03, -5.9814e-03],\n",
            "          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,\n",
            "            1.6068e-02,  2.5879e-02],\n",
            "          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,\n",
            "            2.2964e-03,  2.2339e-02]]]], device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.embeddings.position_embedding.weight', Parameter containing:\n",
            "tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],\n",
            "        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],\n",
            "        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],\n",
            "        ...,\n",
            "        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],\n",
            "        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],\n",
            "        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],\n",
            "       device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.pre_layrnorm.weight', Parameter containing:\n",
            "tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044], device='cuda:0')), ('base_model.model.model.vision_tower.vision_model.pre_layrnorm.bias', Parameter containing:\n",
            "tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],\n",
            "       device='cuda:0'))]\n",
            "Loading dataset from meld_with_rationales.jsonl\n",
            "Dataset size: 100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9828872695fc4c268241a1fb583c5691"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaea884b6a2a4ab18feff3db5fd43d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98d1338352e0484d9ddd81a577c294dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3820e8d0750d429a8d7f2be468fb1caf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running a 1-step dry-run to validate training loop...\n",
            "Dry-run failed — inspect traceback. Error: train() got unexpected keyword arguments: max_steps.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train() got unexpected keyword arguments: max_steps.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2640446047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2640446047.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running a 1-step dry-run to validate training loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dry-run succeeded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2275\u001b[0m             )\n\u001b[1;32m   2276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train() got unexpected keyword arguments: {', '.join(list(kwargs.keys()))}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2278\u001b[0m         \u001b[0;31m# This might change the seed so needs to run first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hp_search_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: train() got unexpected keyword arguments: max_steps."
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "finetune_after_script_b.py\n",
        "\n",
        "Uses robust_llava_loader.load_model_and_tokenizer() (script B output) to load the model,\n",
        "auto-detects good LoRA target_modules, and runs PEFT (LoRA) fine-tuning with trl.SFTTrainer.\n",
        "\n",
        "Usage: python finetune_after_script_b.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "\n",
        "# try to import helper for preparing k-bit training (peft versions vary)\n",
        "try:\n",
        "    from peft import prepare_model_for_kbit_training\n",
        "except Exception:\n",
        "    try:\n",
        "        from peft.utils import prepare_model_for_kbit_training\n",
        "    except Exception:\n",
        "        prepare_model_for_kbit_training = None\n",
        "\n",
        "# Add the src directory to the Python path so we can import robust_llava_loader\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))\n",
        "from robust_llava_loader import load_model_and_tokenizer\n",
        "\n",
        "# --------------------- USER CONFIG ---------------------\n",
        "BASE_MODEL_NAME = \"llava-hf/llava-1.5-7b-hf\"\n",
        "DATASET_PATH = \"meld_with_rationales.jsonl\"   # jsonl containing utterance, sentiment, rationale\n",
        "OUTPUT_DIR = \"./llava-peft-adapters-auto\"\n",
        "USE_4BIT_IF_AVAILABLE = True\n",
        "MAX_SEQ_LENGTH = 512\n",
        "PER_DEVICE_BATCH_SIZE = 2  # Reduced batch size\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 2e-4\n",
        "GRADIENT_ACCUMULATION_STEPS = 2  # Increased accumulation steps\n",
        "SAVE_STEPS = 200\n",
        "LOGGING_STEPS = 20\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# helper: create the training prompt\n",
        "def build_prompt(example):\n",
        "    return (\n",
        "        \"You are a sentiment analysis expert. Analyze the following utterance and provide \"\n",
        "        \"the sentiment along with a step-by-step rationale for your decision.\\n\\n\"\n",
        "        \"### Utterance:\\n\"\n",
        "        f\"{example.get('utterance','')}\\n\\n\"\n",
        "        \"### Analysis:\\n\"\n",
        "        f\"Sentiment: {example.get('sentiment','')}\\n\"\n",
        "        f\"Rationale: {example.get('rationale','')}\"\n",
        "    )\n",
        "\n",
        "# helper: scan model.named_modules() and choose candidate target module name substrings\n",
        "def auto_detect_target_module_names(model, prefer_text=True):\n",
        "    \"\"\"\n",
        "    Returns a list of module-name substrings to use in LoraConfig.target_modules.\n",
        "    Strategy:\n",
        "      - Collect names of submodules that look like projections (q_proj, k_proj, v_proj, out_proj, o_proj)\n",
        "      - Prefer modules under 'model' that contain tokens like 'self_attn', 'attn', 'q_proj' etc.\n",
        "      - If prefer_text=True, try to exclude modules under vision tower (module name containing 'vision' or 'vision_tower')\n",
        "    \"\"\"\n",
        "    proj_patterns = set()\n",
        "    name_list = [n for n, _ in model.named_modules()]\n",
        "\n",
        "    for n in name_list:\n",
        "        # skip top-level empty name\n",
        "        if not n:\n",
        "            continue\n",
        "        # skip vision modules if preferring text modules\n",
        "        if prefer_text and (\"vision\" in n or \"vision_tower\" in n or \"vision_model\" in n):\n",
        "            continue\n",
        "        # find typical projection/fc names in module path\n",
        "        if re.search(r\"(q_proj|k_proj|v_proj|o_proj|out_proj|gate_proj|up_proj|down_proj|fc1|fc2)\", n):\n",
        "            # extract final token (last part after '.')\n",
        "            final = n.split(\".\")[-1]\n",
        "            proj_patterns.add(final)\n",
        "    # fallback if empty\n",
        "    if not proj_patterns:\n",
        "        # default common names\n",
        "        proj_patterns = {\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"}\n",
        "    # keep consistent ordering and return as list\n",
        "    return sorted(list(proj_patterns))\n",
        "\n",
        "# UPDATED: tokenize here and enforce max_length/truncation/padding\n",
        "def format_and_map(example, tokenizer):\n",
        "    text = build_prompt(example)\n",
        "    eos = tokenizer.eos_token or \"\"\n",
        "    full = text + eos\n",
        "    # ensure the tokenizer has a pad token\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n",
        "    encoded = tokenizer(\n",
        "        full,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_SEQ_LENGTH,\n",
        "        return_attention_mask=True,\n",
        "    )\n",
        "    # return input_ids & attention_mask — SFTTrainer can be told to use 'input_ids' as dataset_text_field\n",
        "    return {\n",
        "        \"input_ids\": encoded[\"input_ids\"],\n",
        "        \"attention_mask\": encoded[\"attention_mask\"],\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    # decide 4-bit usage\n",
        "    use_4bit = False\n",
        "    if USE_4BIT_IF_AVAILABLE:\n",
        "        try:\n",
        "            import bitsandbytes  # noqa: F401\n",
        "            use_4bit = True\n",
        "        except Exception:\n",
        "            print(\"bitsandbytes not installed/found — running without 4-bit.\")\n",
        "\n",
        "    # 1) Load model + tokenizer (robust loader)\n",
        "    print(\"Loading model + tokenizer (robust loader)...\")\n",
        "    model, tokenizer = load_model_and_tokenizer(model_name=BASE_MODEL_NAME, use_4bit=use_4bit)\n",
        "    print(\"Loaded model and tokenizer. Model dtype hint:\", getattr(model, \"dtype\", None))\n",
        "    model.config.use_cache = False\n",
        "    try:\n",
        "        model.gradient_checkpointing_enable()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) Auto-detect target_modules for LoRA (based on model module names)\n",
        "    print(\"Auto-detecting candidate LoRA target module name tokens from model.named_modules()...\")\n",
        "    detected = auto_detect_target_module_names(model, prefer_text=True)\n",
        "    print(\"Detected target-module name tokens (candidates):\", detected)\n",
        "\n",
        "    # We'll use these tokens as LoraConfig.target_modules (PEFT expects substrings)\n",
        "    target_modules = detected\n",
        "\n",
        "    # 3) Prepare model for k-bit training (if using 4-bit & helper present)\n",
        "    if use_4bit:\n",
        "        if prepare_model_for_kbit_training is not None:\n",
        "            print(\"Preparing model for k-bit training (peft.prepare_model_for_kbit_training)...\")\n",
        "            model = prepare_model_for_kbit_training(model)\n",
        "        else:\n",
        "            print(\"prepare_model_for_kbit_training not available in this peft version — continuing.\")\n",
        "\n",
        "    # 4) Create LoraConfig and wrap model\n",
        "    lora_cfg = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=target_modules,\n",
        "    )\n",
        "    print(\"Applying LoRA with LoraConfig:\", lora_cfg)\n",
        "    model = get_peft_model(model, lora_cfg)\n",
        "    print(\"PEFT/LoRA applied. Peft model keys:\", list(model.named_parameters())[:5])\n",
        "\n",
        "    # 5) Load and format dataset\n",
        "    print(\"Loading dataset from\", DATASET_PATH)\n",
        "    ds = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n",
        "    print(\"Dataset size:\", len(ds))\n",
        "    # tokenize & create input_ids & attention_mask fields (and remove other columns)\n",
        "    ds = ds.map(lambda ex: format_and_map(ex, tokenizer), remove_columns=ds.column_names)\n",
        "\n",
        "    from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "    # 6) SFTConfig + trainer\n",
        "    # NOTE: removed max_seq_length from SFTConfig (it caused your TypeError)\n",
        "    training_args = SFTConfig(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=use_4bit or (torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory >= 12 * 1024 ** 2),\n",
        "        save_steps=SAVE_STEPS,\n",
        "        logging_steps=LOGGING_STEPS,\n",
        "        save_total_limit=3,\n",
        "        report_to=\"none\",\n",
        "        dataset_text_field=\"input_ids\",   # <-- point trainer to tokenized input_ids field\n",
        "        packing=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=ds,\n",
        "        peft_config=lora_cfg,\n",
        "        args=training_args,\n",
        "    )\n",
        "\n",
        "    # rest remains the same: dry-run, full train, save adapters\n",
        "    print(\"Running a 1-step dry-run to validate training loop...\")\n",
        "    try:\n",
        "        trainer.train(max_steps=1)\n",
        "        print(\"Dry-run succeeded.\")\n",
        "    except Exception as e:\n",
        "        print(\"Dry-run failed — inspect traceback. Error:\", e)\n",
        "        raise\n",
        "\n",
        "    print(\"Starting full training...\")\n",
        "    trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    print(\"Saving adapters to:\", OUTPUT_DIR)\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    print(\"Saved. You can load later with PeftModel.from_pretrained(base_model, OUTPUT_DIR)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkKd6kxXXHG6"
      },
      "outputs": [],
      "source": [
        "# (Empty cell placeholder removed for clarity)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5613a6c3ccd4077ba3b453d07fdda93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a9e5dcada3f439d85db8f5fcb013994",
              "IPY_MODEL_8b63505faecd4cb3bf6740dd7c3d7cfb",
              "IPY_MODEL_2f34c26d434546e5a9788e22b6556187"
            ],
            "layout": "IPY_MODEL_6b7986ae63c940f98d85183bf51d1835",
            "tabbable": null,
            "tooltip": null
          }
        },
        "0a9e5dcada3f439d85db8f5fcb013994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9ad458f171e34f0ea30b1f7940dd3728",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d98cb4daa94d81aed7d5c6107e39ea",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8b63505faecd4cb3bf6740dd7c3d7cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e29c7397e341446b84390c1631351c1a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84e099d27c5c49f19a81a23d1db502aa",
            "tabbable": null,
            "tooltip": null,
            "value": 3
          }
        },
        "2f34c26d434546e5a9788e22b6556187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_75675b02d22f40fbbb27c2cc212522b6",
            "placeholder": "​",
            "style": "IPY_MODEL_69359fafe2b44b85978372ffcd8e4795",
            "tabbable": null,
            "tooltip": null,
            "value": " 3/3 [01:11&lt;00:00, 23.25s/it]"
          }
        },
        "6b7986ae63c940f98d85183bf51d1835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad458f171e34f0ea30b1f7940dd3728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d98cb4daa94d81aed7d5c6107e39ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e29c7397e341446b84390c1631351c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e099d27c5c49f19a81a23d1db502aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75675b02d22f40fbbb27c2cc212522b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69359fafe2b44b85978372ffcd8e4795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5f9d29d9ecb043818ade133cd44a84c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb2a98706d149f3bc80793b43598fc2",
              "IPY_MODEL_6602f1f73dc24fa29191632bb86f2993",
              "IPY_MODEL_1c2b29a5025b4bfcb71546e23eded53f"
            ],
            "layout": "IPY_MODEL_ac06103a3c5b4c0994e9965d00907e55",
            "tabbable": null,
            "tooltip": null
          }
        },
        "4eb2a98706d149f3bc80793b43598fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b2ff0ce8fae5450f8e2d801a3666f3af",
            "placeholder": "​",
            "style": "IPY_MODEL_8215fd903942432ab6d70049c9a5e656",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6602f1f73dc24fa29191632bb86f2993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_eb05168b9551472fa93e7b1e97bcb598",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f7e3ec938e940c8b0befca6351e6277",
            "tabbable": null,
            "tooltip": null,
            "value": 3
          }
        },
        "1c2b29a5025b4bfcb71546e23eded53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bebf5287de214b08b8a42d8f8300a01d",
            "placeholder": "​",
            "style": "IPY_MODEL_76e80cef4cb44cca9a651df506f44b78",
            "tabbable": null,
            "tooltip": null,
            "value": " 3/3 [01:29&lt;00:00, 28.88s/it]"
          }
        },
        "ac06103a3c5b4c0994e9965d00907e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ff0ce8fae5450f8e2d801a3666f3af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8215fd903942432ab6d70049c9a5e656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "eb05168b9551472fa93e7b1e97bcb598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7e3ec938e940c8b0befca6351e6277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bebf5287de214b08b8a42d8f8300a01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e80cef4cb44cca9a651df506f44b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "9828872695fc4c268241a1fb583c5691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624b6256c73b4badbf0ea1e2026ab204",
              "IPY_MODEL_c1d5a7ec2f814aa18b9f3b041bbe19d5",
              "IPY_MODEL_326252cc1c9a4a548408c1fbc3395fa7"
            ],
            "layout": "IPY_MODEL_a5fa9b4432064e738ada0d69c45f2941",
            "tabbable": null,
            "tooltip": null
          }
        },
        "624b6256c73b4badbf0ea1e2026ab204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1c21f344cac14ea2b3fc3016a47d7870",
            "placeholder": "​",
            "style": "IPY_MODEL_8cb466006d51468ea5b241701a62ab6b",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "c1d5a7ec2f814aa18b9f3b041bbe19d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_36e8f1435ef14fd5bbe70ea397b7e09a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e25c80ce5feb4c49ba2aa50f86443011",
            "tabbable": null,
            "tooltip": null,
            "value": 100
          }
        },
        "326252cc1c9a4a548408c1fbc3395fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8fbe14b3c1554fce81ef4e902d680266",
            "placeholder": "​",
            "style": "IPY_MODEL_08552dc1c36a4153bcaed83ec3aea202",
            "tabbable": null,
            "tooltip": null,
            "value": " 100/100 [00:00&lt;00:00, 693.63 examples/s]"
          }
        },
        "a5fa9b4432064e738ada0d69c45f2941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c21f344cac14ea2b3fc3016a47d7870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb466006d51468ea5b241701a62ab6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "36e8f1435ef14fd5bbe70ea397b7e09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25c80ce5feb4c49ba2aa50f86443011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fbe14b3c1554fce81ef4e902d680266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08552dc1c36a4153bcaed83ec3aea202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "aaea884b6a2a4ab18feff3db5fd43d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32be4ec15ba046c88ba26908dfcaf9f2",
              "IPY_MODEL_18dbeb143c7a457b869ccead604a2a29",
              "IPY_MODEL_7ae6dd6740e345b59bbea028026513b4"
            ],
            "layout": "IPY_MODEL_6d673d0921a54fe29039fc3b740abbcf",
            "tabbable": null,
            "tooltip": null
          }
        },
        "32be4ec15ba046c88ba26908dfcaf9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c5da97db2cec462b8bdeaac55d48a736",
            "placeholder": "​",
            "style": "IPY_MODEL_44058f2163494f848e1e4cabee4f418c",
            "tabbable": null,
            "tooltip": null,
            "value": "processor_config.json: 100%"
          }
        },
        "18dbeb143c7a457b869ccead604a2a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8fb70fe7dfa84d07ba932164ea49e53b",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf3f88cf07f431ebfbea9245efe801e",
            "tabbable": null,
            "tooltip": null,
            "value": 173
          }
        },
        "7ae6dd6740e345b59bbea028026513b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cd6c9fd3d0f24a74b937a2c477890aed",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3e34d6d27e400a9e7688281da2e1cf",
            "tabbable": null,
            "tooltip": null,
            "value": " 173/173 [00:00&lt;00:00, 20.4kB/s]"
          }
        },
        "6d673d0921a54fe29039fc3b740abbcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5da97db2cec462b8bdeaac55d48a736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44058f2163494f848e1e4cabee4f418c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8fb70fe7dfa84d07ba932164ea49e53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf3f88cf07f431ebfbea9245efe801e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd6c9fd3d0f24a74b937a2c477890aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3e34d6d27e400a9e7688281da2e1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "98d1338352e0484d9ddd81a577c294dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1c47b8f14ac43aea15fb921b717412a",
              "IPY_MODEL_dad139611a2e407896f092cd45d9bdfa",
              "IPY_MODEL_5cb964ba59124904849432fda04e80d1"
            ],
            "layout": "IPY_MODEL_dc60ab6fe8124d68b35b7d0e894f42f5",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a1c47b8f14ac43aea15fb921b717412a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8deaa933b8d1471d8bbcf1931a9ffe5b",
            "placeholder": "​",
            "style": "IPY_MODEL_87df1593c01c446d9d1bd5d6567c76d3",
            "tabbable": null,
            "tooltip": null,
            "value": "chat_template.json: 100%"
          }
        },
        "dad139611a2e407896f092cd45d9bdfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_028c322ddfb341bca627af68cc716696",
            "max": 701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caffd49dd29c4883ba9e2030fa376893",
            "tabbable": null,
            "tooltip": null,
            "value": 701
          }
        },
        "5cb964ba59124904849432fda04e80d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_25d838218df240d7a63614684962e51b",
            "placeholder": "​",
            "style": "IPY_MODEL_1f93f758b700410f9989b07962f73104",
            "tabbable": null,
            "tooltip": null,
            "value": " 701/701 [00:00&lt;00:00, 59.6kB/s]"
          }
        },
        "dc60ab6fe8124d68b35b7d0e894f42f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8deaa933b8d1471d8bbcf1931a9ffe5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87df1593c01c446d9d1bd5d6567c76d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "028c322ddfb341bca627af68cc716696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caffd49dd29c4883ba9e2030fa376893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25d838218df240d7a63614684962e51b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f93f758b700410f9989b07962f73104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3820e8d0750d429a8d7f2be468fb1caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80d5bb880fde440ca413bee05215954d",
              "IPY_MODEL_7d73e350223946d7a7962e1e8c7f4349",
              "IPY_MODEL_e155cac6392144f68b6cff4d82967005"
            ],
            "layout": "IPY_MODEL_20f947c000484b1b9606dc8fb214cd55",
            "tabbable": null,
            "tooltip": null
          }
        },
        "80d5bb880fde440ca413bee05215954d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2ec0afbf9b654fe2af55fc93930d8b94",
            "placeholder": "​",
            "style": "IPY_MODEL_31cb9ebb639f4bd9b992cc93a4348095",
            "tabbable": null,
            "tooltip": null,
            "value": "preprocessor_config.json: 100%"
          }
        },
        "7d73e350223946d7a7962e1e8c7f4349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b632d5cb63834322b0b4acad68747956",
            "max": 505,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e44da19bd114543b97832352af10e1b",
            "tabbable": null,
            "tooltip": null,
            "value": 505
          }
        },
        "e155cac6392144f68b6cff4d82967005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bb88b1daac4240acb771cb523f7d3634",
            "placeholder": "​",
            "style": "IPY_MODEL_c1a9bd5992274b23aa58b30f621c8252",
            "tabbable": null,
            "tooltip": null,
            "value": " 505/505 [00:00&lt;00:00, 62.0kB/s]"
          }
        },
        "20f947c000484b1b9606dc8fb214cd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec0afbf9b654fe2af55fc93930d8b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31cb9ebb639f4bd9b992cc93a4348095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b632d5cb63834322b0b4acad68747956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e44da19bd114543b97832352af10e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb88b1daac4240acb771cb523f7d3634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a9bd5992274b23aa58b30f621c8252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}